---
title: 'OHI: Tourism and Recreation '
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../src/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---


[REFERENCE RMD FILE: https://cdn.rawgit.com/OHI-Science/ohiprep/master/globalprep/tr/v2017/tr_dataprep.html]

# Summary
This document describes the steps for obtaining the data used to calculate the tourism and recreation goal for the 2018 global assessment.

The general calculation is:
tr = Ep * Sr * Tw
and
Xtr = tr/90th quantile across regions

* Ep = Proportion of workforce directly employed in tourism
* Sr = (S-1)/5; Sustainability of tourism
* Tw = A penalty applied to regions with travel warnings from the US State Department

The following data are used:

* Tourism sustainability: TCCI
* Proportion of workforce directly employed in tourism: (WEF)
* Travel warnings: (U.S. State Department)
* Per capita GDP: (World Bank with gaps filled using CIA data), used to gapfill missing values in Tourism sustainability

# Updates from previous assessment
We discovered that the WEF-Economics Global Competitiveness Index data used to estimate sustainability is not compatible across years.  New methods are used each year and previous year's of data are not recalculated using the updated methods. Consequently, we use the most recent data for all scenario years.  

We were able to update the following data:

* Proportion of jobs in tourism 
* Travel warnings for 2018 (downloaded: 06/28/2018)
* Sustainability


# Some code to set everything up

```{r setup, message=FALSE, warning=FALSE}
#setwd("~/github/ohiprep_v2018/globalprep/tr/v2018") #comment out when knitting

library(devtools)
devtools::install_github("ohi-science/ohicore@dev")
library(ohicore)

source('https://raw.githubusercontent.com/OHI-Science/ohiprep_v2018/master/src/R/common.R')
library(tidyverse)
library(stringr)
library(WDI)

## maximum year of wttc data:
year_max <- 2015

source('R/tr_fxns.R')

```


#Ep: Proportion of workforce directly employed in tourism
These data are from the World Travel & Tourism Council (http://www.wttc.org/).  We use "direct" employment data (eee mazu: globalprep/_raw_data/WTTC/d2017/README.md for instructions on obtaining data). The data extend to 2027, but these values are projections.  The actual data goes to 2015.

These data are cleaned and formatted using the R/process_WTTC.R script. Missing values are gapfilled using the UN georegion information.

```{r wttc prop tourism}

## describe where the raw data are located:
dir_wttc <- file.path(dir_M, 'git-annex/globalprep/_raw_data/WTTC/d2017/raw')

## processing script that formats the WTTC for OHI, saves the following: intermediate/wttc_empd_rgn
source('R/process_WTTC.R', local = TRUE)

## read in the dataset created by above function:
tr_jobs_pct_tour <- read.csv('intermediate/wttc_empd_rgn.csv', stringsAsFactors = FALSE) %>%
                select(rgn_id, year, jobs_pct)

## format data to have complete years/regions and convert percentage of jobs to proportion of jobs
rgn_names <- read.csv('https://raw.githubusercontent.com/OHI-Science/ohi-global/draft/eez/spatial/regions_list.csv', stringsAsFactors = FALSE) %>%
    dplyr::select(rgn_id)

# create data frame with a row for each combination of region id and year
rgn_names <- expand.grid(rgn_id = rgn_names$rgn_id, 
                             year = min(tr_jobs_pct_tour$year):max(tr_jobs_pct_tour$year))
      
tr_data_raw <- rgn_names %>%
    full_join(tr_jobs_pct_tour %>%
                rename(Ep = jobs_pct) %>%
                mutate(Ep = Ep/100) %>%
                mutate(Ep = ifelse(Ep > 1, NA, Ep)),  # Rgn 54, United Arab Emirates appears to have an error bteween 1995-1999 (original Ep value > 100%), this cuts these
              by = c('rgn_id', 'year'))

## gapfill missing data using UN georegion data:
georegions       <- georegions
georegion_labels <- georegion_labels

tr_data_raw <- tr_data_raw %>%
  left_join(georegions, by = 'rgn_id') %>%
  left_join(georegion_labels, by = 'rgn_id') %>%
  select(-r0) %>%
  filter(rgn_id != c(255, 213)) # ditch disputed regions and Antarctica

# Calculate two different gapfill columns using r2 and r1
tr_data_raw_gf <- tr_data_raw %>%
  group_by(year, r2) %>%
  mutate(Ep_pred_r2 = mean(Ep, na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(year, r1) %>%
  mutate(Ep_pred_r1 = mean(Ep, na.rm=TRUE)) %>%
  ungroup()

# first gapfill with r2, if no value available use r1; create column indicating whether value was gapfilled and if so, by what method.
tr_data_raw_gf <- tr_data_raw_gf %>%
  mutate(Ep_all = ifelse(is.na(Ep), Ep_pred_r2, Ep)) %>%
  mutate(Ep_all = ifelse(is.na(Ep_all), Ep_pred_r1, Ep_all)) %>% 
  mutate(gapfilled = ifelse(is.na(Ep) & !is.na(Ep_all), "gapfilled", NA)) %>%
  mutate(method = ifelse(is.na(Ep) & !is.na(Ep_pred_r2), "UN georegion (r2)", NA)) %>%
  mutate(method = ifelse(is.na(Ep) & is.na(Ep_pred_r2) & !is.na(Ep_pred_r1), "UN georegion (r1)", method)) 

# save the data
tr_data_gf <- tr_data_raw_gf %>%
  select(rgn_id, year, gapfilled, method) 

write.csv(tr_data_gf, "output/tr_jobs_pct_tourism_gf.csv", row.names=FALSE)

tr_data <- tr_data_raw_gf %>%
  select(rgn_id, year, Ep=Ep_all) 

write.csv(tr_data, "output/tr_jobs_pct_tourism.csv", row.names=FALSE)


## A quick check to make sure last year's values aren't too crazy different
## (NOTE: the source data has been updated, so there are some changes, but they shouldn't be super different)

old <- read.csv('../v2017/output/tr_jobs_pct_tourism.csv')%>%
  select(rgn_id, year, ep_old=Ep)
new <- read.csv('output/tr_jobs_pct_tourism.csv') %>%
  left_join(old) %>%
  filter(year==2014) %>%
  arrange(ep_old)
new

plot(new$Ep, new$ep_old)
abline(0,1, col="red")
## NOTE: This looks reasonable to me.

```

# Tw: Travel warnings

Primary source of information is from the U.S. State Department  (https://travel.state.gov/content/passports/en/alertswarnings.html)

Secondary source of information: Canada's Government - Travel Advice and Advisories
(https://travel.gc.ca/travelling/advisories)

#### 2018 Assesment
the U.S. State Department updated the way they report the data. This year warnings are reported for every country (not only the ones under a certain risk as it used to be). 
We input the data manualy to an excel file, converted into csv and wrangle the data to merge with data for previous assesments.

Data was download on 06/28/2018

We also looked into Canada's Governement travel warning in order to make sure we capture as many OHI regions as possible. The Canadian government reports 18 more ohi regions including the U.S and U.S territories. 

Data was download on 07/06/2018

#### Notes about getting data:

**For future assesmentes** It would be worthwhile to see if data can be "scrape" directly from the website into R. Maybe taking some time to figure this out because it seems like this will be the new format of the state department travel warning data. Figuring this out now will save us time in the future...and might be faster than doing this by hand.

#### Getting data for 2018 assessment

Step 1: Copy and paste the data for each contry found in:https://travel.state.gov/content/passports/en/alertswarnings.html

Step 2: Manually check for every country if there is any regional warning and the risk factor in each case. If different subregions within a country have different warnings, these are put on two different lines, indicating if the warning is regional.

regional: added if the warning only applies to specific regions within a country

Eg:
assess_year	country	level	                           date	   regional	 location
2018	     Albania	1: Exercise normal precautions	6/18/18			
2018	     Albania	2: Exercise increased caution	  6/18/18	   1	     The southern town of Lazarat

Step 3: Import the csv with 2018 data. Wrangle and clean the new data so it matches long format of tr_travelwarnings_2017.csv

Step 4: Wrangle tr_travelwarnings_2017.csv into long format and adapt risk levels to new way of reporting risk levels (see note below)

Step 5: Join new data with previous assesment data and transform the warnings into a multiplier that is used to calculate tourism and recreation scores.

Risk levels
Up to 2017:
inform: information travelor should be aware of (election violence, be aware due to crime, etc)
risk: risks that trevelors should be aware of ("consider carefully risks of travel", "warns of risks")
avoid_nonessential travel: "defer non-essential travel"
avoid_all: "avoid all travel"
gtfo: get out!!!

For 2018:
Level 1 - Exercise Normal Precautions: This is the lowest advisory level for safety and security risk. There is some risk in any international travel. 
Level 2 - Exercise Increased Caution:  Be aware of heightened risks to safety and security. 
Level 3 - Reconsider Travel: Avoid travel due to serious risks to safety and security.
Level 4 â€“ Do Not Travel:  This is the highest advisory level due to greater likelihood of life-threatening risks. 

Step 6: Convert names to OHI regions and identify NAs. Look for regions with no data in the Canadian Government website and add them to the raw data csv. Make sure to label the column indicting the data source. 

Step 7: Upload the new version of the raw casv (including data from the Canadian Gov).

Step 8: Run the whole scritp again in order to obtain the outcome file with the multiplier for each country. 


```{r}
##Reading and wrangling 2018 data
warn_raw <- read.csv('raw/tr_travelwarning_2018_raw.csv', na.strings = " ") %>% 
  mutate(country = as.character(country)) %>% 
  mutate(level = as.numeric(str_extract(level, '[1,2,3,4]'))) %>% 
  mutate(regional = as.numeric (regional)) %>% 
  select(assess_year, level, country , regional) %>% 
  rename(year= assess_year)
 
##Correct regions that are reported together

##NOTE 1: Northern Saint-Martin and Guadeloupe and Martinique are reported under "French West Indies". The general warning for this region is 1 but is has a regional regional warning for St. Martin. Therefore, Guadeloupe and Martinique will get a level 1 score and Northern Saint-Martin a level 3 (this is according to the data) and not dicounting for regional.
##NOTE 2: Similar than above Israel is reported together with The West Bank and Gaza. The overall warning for the region is level 2, but there are two regional warnings, one for Gaza dn one for the West Bank under a level 4 and 3 respectivly. Israel is getting the overal warning (Level 2), and Gaza and The West Bank are categorized as disputed areas and given two regional warnings according to the data.

warn_improved <- warn_raw %>% 
  dplyr::mutate(rgn_name = ifelse(country == "French West Indies", "Northern Saint-Martin", country)) %>% 
  dplyr::mutate(rgn_name = ifelse(country == "French West Indies" & is.na(regional), "Guadeloupe and Martinique", rgn_name)) %>%
  dplyr::mutate(regional = ifelse(rgn_name == "Northern Saint-Martin", NA, regional)) %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Israel"), "Israel", rgn_name)) %>%
  dplyr::mutate(rgn_name = ifelse(rgn_name == "Israel" & !is.na(regional), "DISPUTED", rgn_name)) 
  
  
##Correct names for regions not identified by the name_2_region

warn_improved <- warn_improved %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Bonaire"), "Bonaire", rgn_name)) %>%
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"ROC"), "Republique du Congo", rgn_name)) %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Kinshasha"), "Democratic Republic of the Congo", rgn_name)) %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Domincan"), "Dominican Republic", rgn_name)) %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"France"), "France", rgn_name)) %>%
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Honduras\xca"), "Honduras", rgn_name)) %>%
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Sao Tome"), "Sao Tome and Principe", rgn_name)) %>%
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Turks and Caicos"), "Turks and Caicos Islands", rgn_name)) %>%
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"United Arab Emirates"), "United Arab Emirates", rgn_name)) %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Line Islands"), "Kiribati", rgn_name)) %>% 
  dplyr::mutate(rgn_name = ifelse(stringr::str_detect(country,"Virgin Islands"), "Virgin Islands", rgn_name)) %>% 
  dplyr::select(-country)


#In this dataset France and Monaco are reported together. This code creates a separate row for each of these regions.

FM <- filter(warn_improved, rgn_name=="France") %>%
  rename(country_old = rgn_name)
FM_subregions <- data.frame(country_old = "France",
                            rgn_name = c("France", "Monaco")) %>%
  left_join(FM) %>%
  select(-country_old)

warn_improved <- warn_improved %>%
  filter(rgn_name != "France") %>%
  rbind(FM_subregions)

#Same with Bonaire, Saba and Sint Estatius: all reported together.
BSS <- filter(warn_improved, rgn_name=="Bonaire") %>%
  rename(country_old = rgn_name)
BSS_subregions <- data.frame(country_old = "Bonaire",
                            rgn_name = c("Bonaire", "Saba", "Sint Eustatius")) %>%
  left_join(BSS) %>%
  select(-country_old)

warn_improved <- warn_improved %>%
  filter(rgn_name != "Bonaire") %>%
  rbind(BSS_subregions)

##Formating data upto 2017. Assigning Levels to old categories:
## inform - Level 1 
## risk - Level 2 
## avoid_nonessential - Level 3 
## avoid_all & gtfo - Level 4

#scores_old = data.frame(category = c("inform", "risk", "avoid_nonessential", "avoid_all", "gtfo"), old_score = c(0, 0.25, 0.75, 1, 1)) 

scores <-  data.frame(level = c(1, 2, 3, 4), score = c(0, 0.25, 0.75, 1)) 

warn_old <- read.csv('raw/tr_travelwarnings_2017.csv') %>%
  select(year = assess_year, rgn_name, inform, risk, avoid_nonessential, avoid_all, gtfo, regional) %>%
  gather("category", "n", 3:7)  %>%
  filter(!is.na(n)) %>%
  select(-n) %>% 
  mutate(level= ifelse(category == 'inform', 1, ifelse(category== 'risk', 2, ifelse(category== 'avoid_nonessential', 3, ifelse(category %in% c('avoid_all', 'gtfo'), 4, NA))))) %>% 
  select(-category) %>% 
  arrange(desc(year), rgn_name) 

#binding old a new data and add scores for each warning level
warn_complete <- warn_improved %>% 
  bind_rows(warn_old) %>% 
  left_join(scores, by="level") %>% 
  group_by(year, rgn_name) %>%
  mutate(warning_count = n()) 

```


The following code is used transform the warnings into a multiplier that is used to calculate tourism and recreation scores: 

```{r travel warnings}

##Note: Adjusting scores for regions that only have one regional report: For 2018 warnings, every contry will have at least 1 warning, therefore the if statement changes to:  ifelse(warning_count %in% 2 & regional %in% 1, score*0.5, score). This is becuase countries with only one regional warn will have 2 warn count, the general inform warning plus the regional warning. If a country has more than one regional warn, then warn count would be >= 3 and their score should not be discounted.

## In the past (data from 2015 to 2017): ifelse(warning_count %in% 1 & regional %in% 1, score*0.5, score). This works because not all countries have a warning so whenever there is one warning_count and regional is 1, then then is means that that country has only a one regional warning which should be discounted. 

warn2 <- warn_complete %>%
  mutate(score = ifelse(year == '2018', ifelse(warning_count %in% 2 & regional %in% 1, score*0.5, score), score)) %>% #year == '2018' will change in the fuure when new assesment years are added. 
  mutate(score = ifelse(year %in% 2017:2015, ifelse(warning_count %in% 1 & regional %in% 1, score*0.5, score), score)) %>% # adjust country-year observations that only have had a single warning that was only applied to specific regions
  summarize(score = mean(score)) %>%
  mutate(multiplier = 1-score) %>%
  select(year, rgn_name, multiplier) %>%
  data.frame()

data.frame(filter(warn_complete, year==2015))
data.frame(filter(warn2, year==2015)) # checked to make sure I got conversions correct, looks good!


#Add rgn_id
warn_rgn <- name_2_rgn(df_in = warn2, 
                       fld_name='rgn_name', 
                       flds_unique=c('rgn_name','year'))

warn_rgn <- warn_rgn %>%
  select(rgn_id, year, multiplier) 
```

Identify which regions are not part of the U.S. State Department warning data for 2018 to be 'gapfilled' with information from Travel Advise from the Canadian Government. 
Once these regions where identfied, we looked them up in the Canadien Gov. Travel Advise web site and updated the the raw data csv and then re-run the chunks above (within the Travel Warning heading)

```{r}
##Creat two variables bringing the georegions and georegion lables from ohi-core. This will allow us to complete the dataframe with all OHI regions.
georegions <- georegions
georegion_labels <- georegion_labels

##Read in OHI regions names to identify missing regions
rgn_lable <- read.csv('https://raw.githubusercontent.com/OHI-Science/ohi-global/draft/eez/layers/rgn_global.csv')

##Read information about inhabited island to compare if some of the missing regions are inhabited
inhab_islands <- read.csv('https://raw.githubusercontent.com/OHI-Science/ohiprep_v2018/master/src/LookupTables/rgn_uninhabited_islands.csv') %>% 
  select(-est_population)

##Filter for information in current assesment year
tw_assessment_yr <- warn_rgn %>% 
  filter(year == 2018)

tw_assessment_yr_complete <- georegions %>%
  dplyr::left_join(tw_assessment_yr) %>%
  dplyr::left_join(georegion_labels, by = 'rgn_id') %>%
  dplyr::select(rgn_id, year, multiplier)

##All regions that do not have data
tw_assessment_yr_NA <- tw_assessment_yr_complete %>% 
  filter(is.na(multiplier)) %>% 
  left_join(rgn_lable) %>% 
  left_join(inhab_islands) %>% 
  select(-year, -multiplier, -rgn_nam)

##Save regions with no data in intermediate folder
write.csv(tw_assessment_yr_NA, 'intermediate/v2018_no_data.csv', row.names=FALSE)

```

Final step is to compare the multipliers assignd in 2017 match to the ones assign in 2018

```{r}
#Compare old multiplier vs new
warn_multi_old <- read_csv("../v2017/output/tr_travelwarnings.csv") %>% 
  rename(multiplier_old= multiplier)

warn_multi_new <- warn_rgn %>% 
  filter(year %in% 2015:2017) %>% 
  left_join(warn_multi_old, by=c("rgn_id", "year"))

plot(warn_multi_new$multiplier, warn_multi_new$multiplier_old)
abline(0,1, col="red")

##No change, that's good!
```

Save the travel warning data in the output folder
```{r}
write.csv(warn_rgn, 'output/tr_travelwarnings.csv', row.names=FALSE)
```



# Ts: Tourism sustainability

These data are from the World Economic Forum's "Travel and Tourism Competitiveness Report" (http://reports.weforum.org/travel-and-tourism-competitiveness-report-2015/downloads/) See mazu: _raw_data/WEF-Economics/ for more details and the raw data.

These data are not compatible across years, so only the most recent year of data is across scenarios.

These data are gapfilled using gdppcppp and UN georegion information (see next section for obtaining and preparing these data).


```{r WEF processing, eval=FALSE}

# read in files
ttci_raw <- read.csv(file.path(dir_M, "git-annex/globalprep/_raw_data/WEF-Economics/d2017/wef_ttci.csv"))


ttci <- ttci_raw %>%
    mutate(country = as.character(country)) %>%
    mutate(country = ifelse(country == "Congo, Democratic Rep.", "Democratic Republic of the Congo", country)) %>%
    mutate(country = ifelse(str_detect(country, "Ivoire"), "Ivory Coast", country))
  
  
ttci_rgn <- name_2_rgn(df_in = ttci, 
                       fld_name='country')

weight_data <- data.frame(country = c("China", "Hong Kong SAR"),
                          population = c(1379000000, 7347000))

ttci_rgn <- ttci_rgn %>%
  arrange(country) %>%
  left_join(weight_data, by = "country") %>%
  mutate(population = ifelse(is.na(population), 1, population)) %>%
  group_by(rgn_id, rgn_name) %>%
  summarize(score = weighted.mean(score, population)) %>%
  select(rgn_id, rgn_name, score)

head(ttci_rgn, 10)

### Save TTCI data file
write_csv(ttci_rgn, 'intermediate/wef_ttci.csv')

```

#### Preparing the gdppcppp data:
These data are used to gapfill missing values in tourism sustainability.  Most of the data are from the World Bank, but CIA data fill some gaps (CIA data is available for only the most recent year).

The Artisanal Opportunities goal uses gdppcppp data, so we will get the data that was processed for that goal. (NOTE: Update the Artisanal Opportunities goal prior to preparing these data)


```{r worldbank}
wb <- read.csv("../../ao/v2017/intermediate/gdppcppp_ohi.csv") %>%
  dplyr::select(rgn_id, year, value)

```

CIA data are used to fill in missing gaps in the gdppcppp data (https://www.cia.gov/library/publications/the-world-factbook/rankorder/2004rank.html)

Downloaded: 9/11/2017

The following code is used to prepare these data for OHI:

```{r cia gdp, eval=FALSE}

cia_gdp <- read.csv('raw/cia_gdp_pc_ppp.csv', stringsAsFactors = FALSE)


splits <- data.frame(country = "Saint Helena, Ascension, and Tristan da Cunha", country2 = c("Saint Helena",
                                                                                             "Ascension",
                                                                                             "Tristan da Cunha")) %>%
  mutate(country = as.character(country),
         country2 = as.character(country2))

cia_gdp <- cia_gdp %>%
  left_join(splits, by='country') %>%
  mutate(country2 = ifelse(is.na(country2), country, country2)) %>%
  select(country=country2, pcgdp_cia = gdppcppp)


cia_gdp_rgn <- name_2_rgn(df_in = cia_gdp, 
                       fld_name='country')

### Collapse regions after weighting by population (regions we include as a single region) - 

population_weights <- data.frame(country = c("Virgin Islands", "Puerto Rico",
                                             "China", "Hong Kong", "Macau",
                                             "Guam", "Northern Mariana Islands"),
                                 population = c(106405, 3725789,
                                         1339724852, 7071576, 636200,
                                         162896, 55023))

cia_gdp_rgn <- cia_gdp_rgn %>%
  left_join(population_weights, by="country") %>%
  mutate(population = ifelse(is.na(population), 1, population)) %>%
  group_by(rgn_id) %>%
  summarize(pcgdp_cia = weighted.mean(pcgdp_cia, population)) %>%
  ungroup() %>%
  filter(rgn_id <= 250) %>%
  select(rgn_id, pcgdp_cia)

write.csv(cia_gdp_rgn, "intermediate/wb_rgn_cia_GDPPCPPP.csv", row.names=FALSE)

```

The following code combines the two gdp datasets and gapfills missing regions using UN georegions.

If there is no World Bank gdppcppp data (pcgdp), the CIA data is used (pcgdp_cia).  The pcgdp2 variable includes both the World Bank and CIA data (with CIA data only used if there is not World Bank data).  The remaining data are estimated using UN geopolitical regions.  Ideally, the mean gdppcppp value is calculated at the r2 scale (gdp_pred_r2) using regions within each class with gdppcppp data.  If there were not enough regions with data at the r2 scale, the average at the r1 scale was used (gdp_pred_r1). The gdp_all variable combines all estimates using the following heirarchy:  World Bank -> CIA -> estimated using mean from r2 UN geopolitical regions -> estimated using mean from r1 UN geopolitical regions.    

```{r gapfill gdp}

### world bank gdp data
gdppcppp <- wb %>%
  select(rgn_id, year, pcgdp = value)

### cia gdp data
gdppcppp2 <- read.csv('intermediate/wb_rgn_cia_GDPPCPPP.csv')


### Use WB data, but if missing, use pcgdp_cia.
### combine with UN georegion data
years <- data.frame(year = min(gdppcppp$year):max(gdppcppp$year))

regions <- georegions %>%
  left_join(georegion_labels, by = 'rgn_id')

gdp_raw <- merge(years, regions, by=NULL) %>%
   left_join(gdppcppp, by = c('rgn_id', 'year')) %>%
  left_join(gdppcppp2, by = c("rgn_id")) 

## quick compare to make sure the CIA and World Bank data are compatible
plot(gdp_raw$pcgdp[gdp_raw$year==2016], gdp_raw$pcgdp_cia[gdp_raw$year==2016])
# a bit of scatter for a few regions, but overall looks good

gdp_raw <- gdp_raw %>%
  mutate(pcgdp2 = ifelse(is.na(pcgdp), pcgdp_cia, pcgdp))

gdp_raw <- gdp_raw %>%
  group_by(r2, year) %>%
  mutate(gdp_pred_r2 = mean(pcgdp2, na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(r1, year) %>%
  mutate(gdp_pred_r1 = mean(pcgdp2, na.rm=TRUE)) %>%
  ungroup() 

gdp_raw_gf <- gdp_raw %>%
  mutate(gdp_all = ifelse(is.na(pcgdp2), gdp_pred_r2, pcgdp2)) %>%
  mutate(gdp_all = ifelse(is.na(gdp_all), gdp_pred_r1, gdp_all)) %>%
  mutate(gapfilled = ifelse(is.na(pcgdp2) & !is.na(gdp_all), "gapfilled", NA)) %>%
  mutate(method = ifelse(is.na(pcgdp2) & !is.na(gdp_pred_r2), "UN georegion (r2)", NA)) %>%
  mutate(method = ifelse(is.na(pcgdp2) & is.na(gdp_pred_r2) & !is.na(gdp_pred_r1), "UN georegion (r1)", method)) 

write_csv(gdp_raw_gf, "intermediate/gdp_raw_gf.csv")

gdp_data_gf <- gdp_raw_gf %>%
  select(rgn_id, year, gapfilled, method) 

write_csv(gdp_data_gf, "intermediate/gdp_gf.csv")

gdp_data <- gdp_raw_gf %>%
  select(rgn_id, year, pcgdp = gdp_all)

write_csv(gdp_data, "intermediate/gdp.csv")

```


The final step is gapfilling the Sustainability data using a linear model with gdppcppp and UN geopolitical regions as predictor variables.  
```{r, eval=FALSE}

sust  <- read.csv('intermediate/wef_ttci.csv', stringsAsFactors = FALSE)

### don't need to gapfill data without tourism data:
## Most recent tourism data is 2015.  

ep_gf <- read.csv("output/tr_jobs_pct_tourism.csv") %>%
  filter(year == 2015) %>%
  select(rgn_id, Ep) %>%
  filter(!is.na(Ep))

# gdp dataframe prepared above (World Bank, CIA, and gapfilled gdp data)
gdp_raw_gf <- read.csv("intermediate/gdp_raw_gf.csv", stringsAsFactors = FALSE) %>% 
  filter(year == 2016) %>%
  select(rgn_id, r0_label, r1_label, r2_label, rgn_label, pcgdp, pcgdp_cia, pcgdp2, gdp_all) 

tr_sust <- gdp_raw_gf %>%
           left_join(sust, by = c("rgn_id")) %>%
          left_join(ep_gf, by = c("rgn_id")) %>%  
          rename(S_score = score) %>%
          filter(rgn_id != 213)

### Add gapfill flag variable 

tr_sust_gf <- tr_sust %>%
  mutate(gapfilled = ifelse(is.na(S_score) & !is.na(Ep), "gapfilled", NA)) %>%
  mutate(method = ifelse(is.na(S_score) & !is.na(Ep) & is.na(pcgdp2), "lm georegion + gdppcppp, with est. gdppcppp", NA)) %>%
  mutate(method = ifelse(is.na(S_score) & !is.na(Ep) & !is.na(pcgdp2), "lm georegion + gdppcppp", method)) %>%
  select(rgn_id, gapfilled, method)

write.csv(tr_sust_gf, "output/tr_sustainability_gf.csv", row.names=FALSE)

  
##############################################################################=
### Gapfilling ----
##############################################################################=


### Gapfill S using r1 and/or r2 regional data and PPP-adjusted per-capita GDP
### Looked at models with a year variable, but wasn't significant and decided to exclude

mod3 <- lm(S_score ~ as.factor(r2_label) + gdp_all, data=tr_sust, na.action = na.exclude)
summary(mod3)
anova(mod3)

mod4 <- lm(S_score ~ as.factor(r1_label) + gdp_all, data=tr_sust, na.action = na.exclude)
summary(mod4)
anova(mod4)

plot(predict(mod3), tr_sust$S_score)
abline(0,1)
plot(predict(mod4), tr_sust$S_score)
abline(0,1)


## Estimate missing data and gapfill
# Some of the r1 levels do not have data and consequently causes a fail.  
# Need to drop these levels so an NA is returned

# Select only r2 column
new_data <- tr_sust[, c("r2_label", "gdp_all")]
unique(tr_sust$r2_label)
r2_w_data <- unique(tr_sust$r2_label[!is.na(tr_sust$S_score)])
new_data_r2 <- new_data %>%
  mutate(r2_label = ifelse(r2_label %in% r2_w_data, r2_label, NA))

# Predict sustainability scores using linear model 3 (using r2 data)
tr_sust$S_score_pred_r2 <- predict(mod3, newdata = new_data_r2)


# Select only r1 column
new_data <- tr_sust[, c("r1_label", "gdp_all")]
unique(tr_sust$r1_label)
r1_w_data <- unique(tr_sust$r1_label[!is.na(tr_sust$S_score)])
new_data_r1 <- new_data %>%
  mutate(r1_label = ifelse(r1_label %in% r1_w_data, r1_label, NA))

# Predict sustainability scores using linear model 4 (using r1 data)
tr_sust$S_score_pred_r1 <- predict(mod4, newdata = new_data_r1)

## some are missing the r1 predictions, but none of these have Ep scores, so not relevant
filter(tr_sust, is.na(S_score_pred_r1))

tr_sust <- tr_sust %>%
  mutate(S_score_2 = ifelse(is.na(S_score), S_score_pred_r2, S_score)) %>%
  mutate(S_score_2 = ifelse(is.na(S_score_2), S_score_pred_r1, S_score_2)) %>%
  mutate(year = '2017') %>%
#  filter(!is.na(Ep)) %>%
  select(rgn_id, year, S_score=S_score_2)

summary(tr_sust)

write_csv(tr_sust, "output/tr_sustainability.csv")

## compare with previous year of data 
compare <- read.csv("../v2015/data/tr_sustainability.csv") %>% # change year
  select(rgn_id, old_S_score = S_score) %>%
  left_join(tr_sust, by = "rgn_id") %>%
  mutate(dif = old_S_score - S_score)

plot(compare$S_score, compare$old_S_score)
abline(0, 1, col="red")
#looks reasonable 

```

