---
title: 'OHI 2016: Sea Surface Temperature Pressure Layer'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../src/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---


# Summary

This script creates the Sea Surface Temperature (SST) layer for the 2018 global Ocean Health Index assessment.


***  

# Updates from previous assessment

The only difference in this layer is the reference point. For OHI 2015, each SST pressure layer was rescaled using the 99.99th quantile of the data from *within* each year. This has been changed to the 99.99th quantile across **all years**. It is a small difference, from 130 to 128 (number of anomalous weeks within a 5 year period).

***

# Data Source

Data comes from [CoRTAD version 5](http://www.nodc.noaa.gov/sog/cortad/)

See prs_sst/v2015/dataprep.R for preparation of the "annual_pos_anomalies" data.  

**Native Data Resolution**: ~4km   
**Description**: 
Cortadv5_SSTA.nc = SST anomalies (weekly SST minus weekly climatological SST), weekly data for all years, degrees Kelvin
Cortadv5_weeklySST.nc =  SST, weekly data for all years, degrees Kelvin  
**Time Range**: 1982 - 2017 (weekly averages across all years)  
**Format**: NetCDF  

***  

# Methods

1. Extreme events per year based calculated as number of times SST anomaly exceeds SST Standard Deviation based on weekly values (annual_pos_anomalies data, see v2015/dataprep.R for analysis).
2. Sum extreme events for five year periods to control for yearly variation.
3. Change in extreme events: Subtract number of extreme events for each five year period from control period (1985-1989).
4. Rescale "Change in extreme events" data to values between 0 and 1 by dividing by the 99.99th quantile among all years of data.

## Setup

```{r setup, message=F,warning=F}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'figs/',message = FALSE, warning = FALSE)

# setwd("globalprep/prs_sst/v2018") # update to reflect current assessment year!
# source("~/github/ohiprep_v2018/src/R/common.R")

library(raster)
library(RColorBrewer)
library(tidyverse)
library(rgdal)
library(doParallel)
library(foreach)
library(sf)
library(ncdf4)
library(httr)

# spatial files, directories, etc
source("~/github/ohiprep_v2018/src/R/spatial_common.R")

dir_data <- file.path(dir_M, "git-annex/globalprep/_raw_data/CoRTAD_sst/d2018")
dir_int  <- file.path(dir_M, "git-annex/globalprep/prs_sst/v2018/int")

yrs <- 1982:2017
cols <- rev(colorRampPalette(brewer.pal(11, 'Spectral'))(255)) # rainbow color scheme
land <- regions %>% subset(rgn_type %in% c("land", "land-disputed", "land-noeez"))
```

***

## Get new data if available

```{r get new data}
months <- str_pad(1:12, 2, pad = "0")

## download URL
url <- "https://data.nodc.noaa.gov/cortad/Version6"

## retrieve the netcdf data, SSTA (~98GB) and WeeklySST (~28GB)
## these take like 2 hours, it's a lot of data!!!
ssta <- sprintf("%s/cortadv6_SSTA.nc", url)
ssta_filename <- file.path(dir_M, "git-annex/globalprep/_raw_data/CoRTAD_sst/d2018/cortadv6_SSTA.nc")
ssta_res <- httr::GET(ssta, write_disk(ssta_filename))

weekly_sst <- sprintf("%s/cortadv6_WeeklySST.nc", url)
weekly_sst_filename <- file.path(dir_M, "git-annex/globalprep/_raw_data/CoRTAD_sst/d2018/cortadv6_WeeklySST.nc")
weekly_sst_res <- httr::GET(weekly_sst, write_disk(weekly_sst_filename))

closeAllConnections()
```

***

## Generate annual positive anomalies (redo each year? reuse set of years like considering for UV?)

```{r generate annual positive anomalies}

ssta         <- stack(list.files(dir_data, pattern = "SSTA.nc", 
                                 full.names = TRUE), varname = "SSTA")
weekly_sst   <- stack(list.files(dir_data, pattern = "WeeklySST.nc", 
                                 full.names = TRUE), varname = "WeeklySST")

names_ssta   <- names(ssta)
names_weekly <- names(weekly_sst)


## create weekly standard deviations across all years
for(i in 1:53){
  s = stack()
  
  for (j in yrs){
    w = which(substr(names_weekly, 2, 5) == j)[i] 
    if(is.na(w)) next() # most years don't have 53 weeks
    w_week = weekly_sst[[w]]
    s = stack(s, w_week)
  }
  
  sd = calc(s, fun = function(x){sd(x, na.rm = TRUE)},
            progress = "text",
            filename = file.path(dir_int, sprintf("sd_sst_week_%s.tif", i)))
}

## calculate annual positive anomalies
for (j in yrs){
  s = stack()
  
  for (i in 1:53){
    sd = raster(paste0("int/sd_sst_week_", i, ".tif")) # sd for week
    w = which(substr(names_ssta, 2, 5) == j)[i]
    if(is.na(w)) next()
    w_ssta = ssta[[w]] # subset the week/year anomaly
    
    count = overlay(w_ssta, sd, fun = function(x, y){ifelse(x > y, 1, 0)},
                    progress = "text") # compare to average anomaly for that week 
    s = stack(s, count)
  }
  
  year = calc(s, fun = function(x){sum(x, na.rm = TRUE)},
              progress ="text",
              filename = file.path(dir_int, sprintf("annual_pos_anomalies_sd_%s.tif", j)),
              overwrite = TRUE)
}
```


## Create 5 year cumulative sum of extreme events and calculate difference from historical

```{r cumulative sum of extreme events, eval = F}

anom_files <- list.files(dir_int, pattern = "annual_pos_anomalies", full.names = TRUE)

## get 5 year aggregates
ref_years <- c(grep(c('1985'), anom_files), grep(c('1986'), anom_files), grep(c('1987'), anom_files), grep(c('1988'), anom_files), grep(c('1989'), anom_files))

ref <- stack(l[ref_years]) %>% 
    sum(.) # This is the time period we are using for historical comparison (1985 - 1989)

  
  registerDoParallel(10)  
  
foreach(i = 1986:2008)%dopar%{ #i=2005
  
  print(i)
  
  yrs <- c(i:(i+4))
  
  s   <- stack(l[substr(l,81,84) %in% yrs]) %>% 
    sum(.)
  
  diff = overlay(s, ref, fun=function(x,y){x-y}) %>% #calculate difference between recent 5 year cumulative sum and historical (1985-1989)
          mask(land, inverse=TRUE)
  
  writeRaster(diff,
              filename = paste0('int/sst_diff_ocean_',yrs[1], '-', yrs[5],'.tif'), overwrite=TRUE)
   
}
```


##Reference Point

The layers are rescaled using a single reference point, the 99.99th quantile across all difference rasters.

```{r ref}

diffs <- list.files('int',pattern = 'diff',full.names=T)

#get data across all years
vals <- c()

for(i in 1:length(diffs)){
  print(i)
  
  m <- diffs[i]%>%
    raster()%>%
    getValues()
  
  vals <- c(vals,m)
  
}

#get min, max and 99.99th quantile

min_v <- min(vals,na.rm=T)
max_v <- max(vals,na.rm=T)
resc_num  <- quantile(vals,prob=0.9999,na.rm=T) ### 128

rescale <- read.csv("../../supplementary_information/v2016/reference_points_pressures.csv")
rescale$ref_point[rescale$pressure == "Sea Surface Temperature"] <- resc_num 
write.csv(rescale, "../../supplementary_information/v2016/reference_points_pressures.csv", row.names=FALSE)

```

The minimum value is `r min_v`, maximum value is `r max_v` and the reference point is `r resc_num`.

## Rescaling

```{r rescale, eval=F}
sprintf('Rescaling')

diffs <- list.files('int',pattern = 'diff',full.names=T)

resc_num <- read.csv("../../supplementary_information/v2016/reference_points_pressures.csv") %>%
  filter(pressure == "Sea Surface Temperature") %>%
  .$ref_point
resc_num <- as.numeric(as.character(resc_num))

foreach(i = 1:length(diffs)) %dopar%{

  r             <- raster(diffs[i])
  
  yrs           <- substr(diffs[i], 20, 28)
  
  projection(r) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
  
  out = projectRaster(r, crs=mollCRS, over=TRUE) %>%
        calc(., fun=function(x){ifelse(x>0, ifelse(x>resc_num, 1, x/resc_num), 0)}) %>%
        resample(., ocean, method='ngb', filename=paste0(dir_M, '/git-annex/globalprep/prs_sst/v2016/output/sst_',yrs,'_1985-1989.tif'), overwrite=TRUE)

}
```

***

#Results

```{r results}
res <- list.files(file.path(dir_M, 'git-annex/globalprep/prs_sst/v2016/output'), full.names = TRUE)

plot(raster(res[23]), col=cols, axes=F, main = 'Sea Surface Temperature Pressure Layer \n OHI 2016')

```

***

# Citation information  

Selig, E.R., K.S. Casey, and J.F. Bruno (2010), New insights into global patterns of ocean temperature anomalies: implications for coral reef health and management, Global Ecology and Biogeography, DOI: 10.1111/j.1466-8238.2009.00522.x.

