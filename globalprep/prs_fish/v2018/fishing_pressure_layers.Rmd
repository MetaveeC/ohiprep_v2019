---
title: "Global Fisheries Catch"
output: html_document
---

# Summary

The commercial fishing pressure layers are created from spatialized catch by gear data provided by Watson (2018), and net primary production data from the Vertically Generalized Production Model [(VGPM)](http://www.science.oregonstate.edu/ocean.productivity/) as described in [Behrenfeld and Falkowski (1997)](http://www.science.oregonstate.edu/ocean.productivity/references/L&O%201997a.pdf).

This script prepares and formats the IMAS Global Fisheries Catch raw data into intermediate data by combining CatchInd_XXXX_XXXX and CatchNInd_XXXX_XXXX rds files wtih Index.csv and Cells.csv as well as a single file with all years.

# Updates from previous assessment

No longer using gear type to classify catch data as high or low bycatch, since the IMAS data now provides values for **discards**, which we consider as bycatch. Previously, the raw catch data was all in a single file. This year, we have to combine across three different data tables: catch data (CatchInd_XXXX_XXXX), master index file with country name, species, etc (Index.csv), and geospatial information (Cells.csv).

One other change from last year is that we will gapfill the missing NPP data prior to using. We correct for system productivity by dividing catch by NPP: [quick review](https://www.researchgate.net/publication/312614653_Reconciling_fisheries_catch_and_ocean_productivity)

# Data Source

**Reference**: Watson, R. A. and Tidd, A. 2018. Mapping nearly a century and a half of global marine fishing: 1869â€“2015. Marine Policy, 93, pp. 171-177. [(Paper URL)](https://doi.org/10.1016/j.marpol.2018.04.023)

**Downloaded**: July 17, 2018 from [IMAS portal](http://data.imas.utas.edu.au/portal/search?uuid=ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0) - clikc on download tab, step 3

**Description**:  Global fisheries landings data per cell separated by Industrial versus Non-Industrial catch, IUU, and discards.

**Native data resolution**:   

**Time range**: 1950 - 2015

**Format**:  CSV format

**Additional Information**: [Metadata](http://metadata.imas.utas.edu.au/geonetwork/srv/eng/metadata.show?uuid=ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0), [Supplementary Material](https://ars.els-cdn.com/content/image/1-s2.0-S0308597X18300605-mmc1.docx)


***
  
# Setup

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}

library(tidyverse)
library(purrr)

source("https://rawgit.com/OHI-Science/ohiprep_v2018/master/src/R/common.R")

rawFolder <- file.path(dir_M, "git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018")

```

# Import Raw Data

* Industrial Catch (1950 - 1954) - reported, iuu, and discard catch data for each cell location and unique identifier
* Master Index File (Index.csv) - information associated with the unique identifiers in the Industrial Catch data
* Spatial Cells Reference (Cell.csv) - contains geospatial information associated wtih the Industrial Catch data

```{r}

## Save download url suffixes 
web_years <- c("Ind_1950_1954", "Ind_1955_1959", "Ind_1960_1964", "Ind_1965_1969", 
               "Ind_1970_1974", "Ind_1975_1979", "Ind_1980_1984", "Ind_1985_1989",
               "Ind_1990_1994", "Ind_1995_1999", "Ind_2000_2004", "Ind_2005_2009", 
               "Ind_2010_2014", "Ind_2015_2019", "NInd_1950_1954", "NInd_1955_1959",
               "NInd_1960_1964", "NInd_1965_1969", "NInd_1970_1974", "NInd_1975_1979",
               "NInd_1980_1984", "NInd_1985_1989", "NInd_1990_1994", "NInd_1995_1999", 
               "NInd_2000_2004", "NInd_2005_2009", "NInd_2010_2014", "NInd_2015_2019")

reference <- c("Cells", "Index")

## Download reference data from web and save into mazu
for(ref in reference){ # ref <- "Ind_1950_1954"
  
  data <- read.csv(sprintf("http://data.imas.utas.edu.au/attachments/ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0/%s.csv", ref))
  
  write.csv(data, file.path(dir_M, sprintf("git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018/%s.csv", ref)), row.names=F)
  
}

## Download catch data from web and save into mazu
for(web_year in web_years){ # web_year <- "Ind_1950_1954"

data <- read.csv(sprintf("http://data.imas.utas.edu.au/attachments/ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0/Catch%s.csv", web_year))

saveRDS(data, file.path(dir_M, sprintf("git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018/Catch%s.rds", web_year)))

}

```

# Explore Data

Filter master file to only include `ID`, `Year`, `CountryName`, `TaxonName`, `CommonName`, `FleetGearName` (I actually don't think we will need the `CountryName` or `FleetGearName`, but it might be interesting).
```{r}

## Look at single catch file
data <- readRDS(file.path(rawFolder,"CatchInd_1950_1954.rds"))
DT::datatable(head(data))

## Master index file
master <- read.csv(file.path(rawFolder,"Index.csv")) %>% 
  select(ID, Year, CountryName, TaxonName, CommonName, FleetGearName)
DT::datatable(head(master))

## Spatial cells reference
spatialCells <- read.csv(file.path(rawFolder,"Cells.csv"))
DT::datatable(head(spatialCells))

```

Test to see whether the values for **IndReported**, **IndIUU**, and **IndDiscards** in the Master Index File are sum totals of Clams cockles arkshells in the Republic of Korea in year 1953.
```{r}
korea_clam <- data %>% 
  filter(ID == 491423) %>% 
  mutate(tot_Reported = sum(Reported),
         tot_IUU = sum(IUU),
         tot_Discards = sum(Discards))

master_check <- master %>%
  filter(ID == 491423)

## IndReported, IndIUU, IndDiscards should match tot_Reported, tot_IUU, and tot_Discards
DT::datatable(head(korea_clam))
head(master_check)

```

# Methods

## Wrangle 

Combine the Master Index and Spatial Cells with the CatchInd and CatchNInd files.

### Function for Combining Files

Create function to read in each file name, combine with Index and Cells data frame, and save everything into one single data file.

```{r}

## Create empty data frame to combine all catch information
bigDataFrame <- data.frame()

## Set function to read in each file, combine with Index.csv and Cells.csv, and save back into mazu
combine_fis <- function(x) {
  
  ## This will be the name of the data frame (w/o extension)
  name <- basename(x) %>% 
    tools::file_path_sans_ext()
  ## Save the data frame into R's memory
  name <- readRDS(x)
  
  ## Create a totals column
  df <- name %>%
    mutate(Landings = Reported+IUU) %>% 
    left_join(master, by = "ID") %>% 
    left_join(spatialCells, by = "Cell")
  
  ## Save intermediate files into mazu with same name as raw
  saveRDS(df, file.path(rawFolder,"int",basename(x)))
  
  ## Add catch data to single data frame
  rbind(df,bigDataFrame)
   
}

```

### Industrial Catch Data

Create list of industrial catch file names and apply the `combine_fis` function to save each individual 5-year interval catch data. Then, create a single file that has all years of data.

The `combine_fis` process should take about 7 minutes. Saving all years into a single file with `saveRDS` will take about 4 minutes.
```{r}

ind_files <- dir(rawFolder, pattern ="CatchInd", full.names=TRUE)

## Wrangle and save each 5-year interval of data
indCatch <- map_df(ind_files, combine_fis)
## Save all years into single file
saveRDS(indCatch, file.path(rawFolder,"int/CatchInd_all.rds"))

```

### Non-industrial Catch Data

```{r}

nind_files <- dir(rawFolder, pattern ="CatchNInd", full.names=TRUE)

## Apply the combine_fis function, which saves each 5-year catch data
nindCatch <- map_df(nind_files, combine_fis)
## Save the 14 separate catch files into a single one
saveRDS(nindCatch, file.path(rawFolder,"int/CatchNInd_all.rds"))

```

