---
title: 'OHI 2017: Commercial Fishing Pressure Layers '
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 1
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../src/templates/ohi_hdr.html'
pdf_document:
  toc: true
---

# Summary

The commercial fishing pressure layers are created from spatialized catch by gear data provided by Watson (2018), and net primary production data from the Vertically Generalized Production Model [(VGPM)](http://www.science.oregonstate.edu/ocean.productivity/) as described in [Behrenfeld and Falkowski (1997)](http://www.science.oregonstate.edu/ocean.productivity/references/L&O%201997a.pdf).

This script prepares and formats the IMAS Global Fisheries Catch raw data into intermediate data by combining CatchInd_XXXX_XXXX and CatchNInd_XXXX_XXXX rds files wtih Index.csv and Cells.csv as well as a single file with all years.

# Updates from previous assessment

No longer using gear type to classify catch data as high or low bycatch, since the IMAS data now provides values for **discards**, which we consider as bycatch. Previously, the raw catch data was all in a single file. This year, we have to combine across three different data tables: catch data (CatchInd_XXXX_XXXX), master index file with country name, species, etc (Index.csv), and geospatial information (Cells.csv).

One other change from last year is that we will gapfill the missing NPP data prior to using. We correct for system productivity by dividing catch by NPP: [quick review](https://www.researchgate.net/publication/312614653_Reconciling_fisheries_catch_and_ocean_productivity)

# Data Source

**Reference**: Watson, R. A. and Tidd, A. 2018. Mapping nearly a century and a half of global marine fishing: 1869â€“2015. Marine Policy, 93, pp. 171-177. [(Paper URL)](https://doi.org/10.1016/j.marpol.2018.04.023)

**Downloaded**: July 17, 2018 from [IMAS portal](http://data.imas.utas.edu.au/portal/search?uuid=ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0) - clikc on download tab, step 3

**Description**:  Global fisheries landings data per cell separated by Industrial versus Non-Industrial catch, IUU, and discards.

**Native data resolution**:   

**Time range**: 1950 - 2015

**Format**:  CSV format

**Additional Information**: [Metadata](http://metadata.imas.utas.edu.au/geonetwork/srv/eng/metadata.show?uuid=ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0), [Supplementary Material](https://ars.els-cdn.com/content/image/1-s2.0-S0308597X18300605-mmc1.docx)


***
  
# Setup

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}

library(tidyverse)
library(purrr)

source("https://rawgit.com/OHI-Science/ohiprep_v2018/master/src/R/common.R")

rawFolder <- file.path(dir_M, "git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018")

```

# Import Raw Data

* Industrial Catch (1950 - 1954) - reported, iuu, and discard catch data for each cell location and unique identifier
* Master Index File (Index.csv) - information associated with the unique identifiers in the Industrial Catch data
* Spatial Cells Reference (Cell.csv) - contains geospatial information associated wtih the Industrial Catch data

```{r}

## Save download url suffixes 
web_years <- c("Ind_1950_1954", "Ind_1955_1959", "Ind_1960_1964", "Ind_1965_1969", 
               "Ind_1970_1974", "Ind_1975_1979", "Ind_1980_1984", "Ind_1985_1989",
               "Ind_1990_1994", "Ind_1995_1999", "Ind_2000_2004", "Ind_2005_2009", 
               "Ind_2010_2014", "Ind_2015_2019", "NInd_1950_1954", "NInd_1955_1959",
               "NInd_1960_1964", "NInd_1965_1969", "NInd_1970_1974", "NInd_1975_1979",
               "NInd_1980_1984", "NInd_1985_1989", "NInd_1990_1994", "NInd_1995_1999", 
               "NInd_2000_2004", "NInd_2005_2009", "NInd_2010_2014", "NInd_2015_2019")

reference <- c("Cells", "Index")

## Download reference data from web and save into mazu
for(ref in reference){ # ref <- "Ind_1950_1954"
  
  data <- read.csv(sprintf("http://data.imas.utas.edu.au/attachments/ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0/%s.csv", ref))
  
  write.csv(data, file.path(dir_M, sprintf("git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018/%s.csv", ref)), row.names=F)
  
}

## Download catch data from web and save into mazu
for(web_year in web_years){ # web_year <- "Ind_1950_1954"

data <- read.csv(sprintf("http://data.imas.utas.edu.au/attachments/ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0/Catch%s.csv", web_year))

saveRDS(data, file.path(dir_M, sprintf("git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018/Catch%s.rds", web_year)))

}

```

# Explore Data

Read in Master Index file, Spatial cells, and a single 5-year Catch dataset. 

Filter master file to only include `ID`, `Year`, `CountryName`, `TaxonName`, `CommonName`, `FleetGearName` (I actually don't think we will need the `CountryName` or `FleetGearName`, but it might be interesting).

```{r}

## Master index file
master <- read.csv(file.path(rawFolder,"Index.csv")) %>% 
  select(ID, Year, CountryName, TaxonName, CommonName, FleetGearName)
DT::datatable(head(master))

## Spatial cells reference
spatialCells <- read.csv(file.path(rawFolder,"Cells.csv"))
DT::datatable(head(spatialCells))

```

```{r}

## Look at single catch file
data <- readRDS(file.path(rawFolder,"CatchInd_1950_1954.rds"))
DT::datatable(head(data))

```

Test to see whether the values for **IndReported**, **IndIUU**, and **IndDiscards** in the Master Index File are sum totals of Clams cockles arkshells in the Republic of Korea in year 1953.
```{r}

korea_clam <- data %>% 
  filter(ID == 491423) %>% 
  mutate(tot_Reported = sum(Reported),
         tot_IUU = sum(IUU),
         tot_Discards = sum(Discards))

master_check <- master %>%
  filter(ID == 491423)

## IndReported, IndIUU, IndDiscards should match tot_Reported, tot_IUU, and tot_Discards
DT::datatable(head(korea_clam))
head(master_check)

```

# Methods

## Wrangle 

### Combine Fisheries Files

1. Combine the Master Index and Spatial Cells with the CatchInd and CatchNInd files.
2. Save each year of data as a separate file into: "globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2018/int"

**Function for Combining & Saving Files**: Create function to read in each file name, combine with Index and Cells data frame, and save each year of catch data into a separate file.

```{r}

## Set function to read in each file, combine with Index.csv and Cells.csv, and save each year of data back into mazu
combine_fis <- function(x) {

  ## Read in the catch data
  ## Create a total Landings column
  ## Join with master and spatial cells file
  df <- readRDS(x) %>%
    mutate(Landings = Reported+IUU) %>% 
    left_join(master, by = "ID") %>% 
    left_join(spatialCells, by = "Cell")
  
  
  ## Save each individual year as a single file
  five_years <- sort(unique(df$Year)) 
  
  for(yr in five_years){
    print(yr) # will show you your progress
    
    single_yr_df <- df %>%
      filter(Year == yr)
    
    ## Save files with prefix CatchInd or CatchNInd
    ## Remove the suffix starting with '_' to get CatchInd or CatchNInd
    ind_Nind <- basename(x) %>% 
      tools::file_path_sans_ext() %>% 
      str_remove("_.*") # remove everything after the first underscore
    
    write_rds(single_yr_df, paste0(rawFolder, "/int/", ind_Nind, "_", yr, ".rds"))
  }
  
  }

```

**Industrial Catch Data**

* Create list of industrial catch file names and apply the `combine_fis` function to save each individual 5-year interval catch data. Then, create a single file that has all years of data.
* The `combine_fis` process should take about 7 minutes. Saving all years into a single file with `saveRDS` will take about 4 minutes.

```{r}

ind_files <- dir(rawFolder, pattern ="CatchInd", full.names=TRUE)

## Wrangle and Save Each Year of Data Separately
indCatch <- map_df(ind_files, combine_fis)

```

**Non-industrial Catch Data**

```{r}

nind_files <- dir(rawFolder, pattern ="CatchNInd", full.names=TRUE)

## Wrangle and Save Each Year of Data Separately
nindCatch <- map_df(nind_files, combine_fis)

```


### Convert to Annual Catch Rasters

**Industrial Catch Data**

```{r}

watson_data <- list.files(file.path(rawFolder, 'int'), full.names=TRUE, pattern = 'CatchInd')

years = c(2003:2014)

registerDoParallel(10) #register cores

foreach(file = watson_data) %dopar% { # file = watson_data[1]
  
data <- readRDS(file)

yrs <- unique(data$Year)

for(i in 1:length(yrs)){
  print(i)
  
yr = yrs[i]
  
yr_data <- data%>%
            filter(Year == yr)%>%
            left_join(gear_taxa, by = c('Taxonkey','TaxonName','CommonName', 'Gear', 'GearName'))

write_rds(yr_data,path = paste0(file.path(dir_M),'/git-annex/impact_acceleration/stressors/comm_fish/int/catch_annual_data/catch_data_',yr,'.rds'))

}
}

```




### Tidy Data

* Filter data to include current year and previous 4 years (so the 2014 pressure raster would be the yearly average of 2010 to 2014 catch data).
* Group by everything except year (and Landings and Discards) and then average the Landings and Discard data across years
* Group by cell and summarize sum of **Landings** and **Discards**

Note: `indCatch` is quite a large file. May have an error if you read it back in from mazu that looks something like:

> Error in readRDS(file.path(rawFolder, "int/CatchInd_all.rds")) : 
  error reading from connection


```{r}

recentYR <- max(indCatch$Year)
years <- recentYR:(recentYR-4) # want 5 years

# years = c(2003:2014)
# 
# foreach(yr = years) %dopar%{ #yr = 2014
#   
#   #read in raw data for the year
#   raw <- readRDS(paste0(file.path(dir_M,'marine_threats/impact_acceleration/stressors/comm_fish/int/catch_data_'),yr,'.rds'))
#   
#   #high bycatch
#   high <- raw %>%
#           dplyr::filter(bycatch == "high") %>%
#           rowwise() %>%
#           dplyr::mutate(catch = sum(LSF_CR, IUU_CR, Discards_CR, na.rm=TRUE) * 1000) %>% #there shouldnt be NAs but just in case, converting from tonnes to kg to get rid of low values
#           dplyr::group_by(Seq) %>%
#           dplyr::summarise(cell_catch = sum(catch))
#           
#     #rasterize catch by swapping cell ids with 
# raster::subs(saup_rast, high, by = 1, which = 2, subsWithNA=TRUE, filename = paste0('int/high_bycatch/annual_catch/high_bc_',yr,'.tif'), overwrite=TRUE) 
#   
#   #low bycatch
#   low <- raw%>%
#           filter(bycatch == "low")%>%
#           rowwise()%>%
#           mutate(catch = sum(LSF_CR, IUU_CR, Discards_CR, na.rm=TRUE) * 1000)%>% #there shouldnt be NAs but just in case
#           group_by(Seq)%>%
#           summarise(cell_catch = sum(catch))
# 
# 
# raster::subs(saup_rast, low, by = 1, which = 2, subsWithNA=TRUE, filename = paste0('int/low_bycatch/annual_catch/low_bc_',yr,'.tif'),overwrite=T) 
#   
#   #artisanal bycatch
#   artisanal <- raw%>%
#                group_by(Seq)%>%
#               summarise(cell_catch = sum(SSF_CR * 1000)) #small scale fisheries catch rate
#   
# raster::subs(saup_rast, artisanal, by = 1, which = 2, subsWithNA=TRUE, filename = paste0('int/artisanal/annual_catch/art_',yr,'.tif'),overwrite=T)
# }
```

